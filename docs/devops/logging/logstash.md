---
title: Logstash
description: Обзор Logstash, компонента стека ELK для серверной обработки логов.
---

# Logstash: Серверная обработка данных

!!! abstract "Тезис"
    **Logstash** — это серверный инструмент для обработки данных с открытым исходным кодом, который является ключевой частью стека **ELK (Elasticsearch, Logstash, Kibana)**. Он принимает данные из множества источников, преобразует их и отправляет в место назначения, чаще всего в Elasticsearch.

---

## Ключевые возможности

-   **Мощная обработка**: Широкий набор фильтров для парсинга (Grok), обогащения (например, GeoIP), и структурирования данных.
-   **Надежность**: Поддержка постоянных очередей (persistent queues) для защиты от потери данных при сбоях.
-   **Большая экосистема**: Интеграция с сотнями источников и мест назначения через плагины.
-   **Гибкость**: Позволяет создавать сложные конвейеры (pipelines) для обработки данных.

---

## Архитектура

Конвейер Logstash состоит из трех частей: **inputs**, **filters**, **outputs**.

!!! example "Схема работы Logstash"
    ```plaintext
    +----------+     +------------------+     +------------------+
    |  Input   | --> | Logstash Pipeline| --> |      Output      |
    | (e.g.    |     | +--------------+ |     | (e.g. Elasticsearch)
    | Beats,   |     | |    Filter    | |     |
    | Kafka)   |     | | (e.g. Grok)  | |     |
    +----------+     | +--------------+ |     |
                   | |    Filter    | |     |
                   | +--------------+ |     |
                   +------------------+     +
    ```

-   **Inputs**: Принимают данные (например, от `Filebeat` или из `Kafka`).
-   **Filters**: Обрабатывают и преобразуют данные. **Grok** — один из самых популярных фильтров для парсинга неструктурированных логов.
-   **Outputs**: Отправляют обработанные данные (например, в `Elasticsearch`).

---

## Пример конфигурации

!!! example "Пример `logstash.conf`"
    ```aconf
    input {
      beats {
        port => 5044
      }
    }

    filter {
      grok {
        match => { "message" => "%{COMBINEDAPACHELOG}" }
      }
      geoip {
        source => "clientip"
      }
    }

    output {
      elasticsearch {
        hosts => ["http://elasticsearch:9200"]
        index => "weblogs-%{+YYYY.MM.dd}"
      }
    }
    ```
    Этот конфиг принимает данные от Filebeat, парсит логи Apache с помощью Grok, обогащает их данными GeoIP и отправляет в Elasticsearch.

---

## Logstash vs Fluentd/Vector

-   **Logstash** исторически был основным инструментом для обработки данных в стеке ELK. Он мощный, но ресурсоемкий из-за работы на JVM.
-   **Fluentd** часто используется как более легковесная альтернатива, особенно в мире Kubernetes.
-   **Vector** является самым современным и производительным решением, но с менее зрелой экосистемой плагинов.

!!! success "Рекомендация"
    В современных системах **Logstash** часто заменяют на более легковесные альтернативы. Однако он остается востребованным в сложных сценариях обработки данных, где требуется его богатый набор фильтров и плагинов.
